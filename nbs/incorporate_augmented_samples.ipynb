{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f53f13a0-2585-468e-afda-7578509d43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7ac79",
   "metadata": {},
   "source": [
    "### Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5c34dc0-4408-4868-bc83-98711f9eb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49b292b3-0b5b-4019-8075-f99631914db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the image directory to the filenames\n",
    "prefix_to_add = 'images_clipped_buffered/'\n",
    "df['file_name'] = prefix_to_add + df['file_name']\n",
    "\n",
    "# Find rows where images correlate with more than one bounding box\n",
    "duplicate_rows = df[df.duplicated(subset=['file_name'], keep=False)]\n",
    "\n",
    "# Create a separate dataframe from those rows\n",
    "duplicate_df = df[df.duplicated(subset=['file_name'], keep=False)].copy()\n",
    "\n",
    "# Remove those rows from the original dataframe\n",
    "df_filtered = df.copy()\n",
    "df_filtered.drop_duplicates(subset=['file_name'], keep=False, inplace=True)\n",
    "\n",
    "# Print the two dataframes\n",
    "print(\"Original DataFrame:\")\n",
    "print(len(df_filtered))\n",
    "print(\"\\nDuplicate DataFrame:\")\n",
    "print(len(duplicate_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f48bfbd-ad1f-4bb7-a94c-c8114f910a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the augmented images and path info\n",
    "extras_completeness_prefix = '~/data/images_clipped_buffered_augmented_completeness/'\n",
    "completeness_prefix = 'images_clipped_buffered_augmented_completeness/'\n",
    "extras_completeness = glob.glob(f\"{extras_completeness_prefix}**/**/*.jpg\")\n",
    "extras_condition_prefix = '~/data/images_clipped_buffered_augmented_condition/'\n",
    "condition_prefix = 'images_clipped_buffered_augmented_condition/'\n",
    "extras_condition = glob.glob(f\"{extras_condition_prefix}**/**/*.jpg\")\n",
    "extras_material_prefix = '~/data/images_clipped_buffered_augmented_material/'\n",
    "material_prefix = 'images_clipped_buffered_augmented_material/'\n",
    "extras_material = glob.glob(f\"{extras_material_prefix}**/**/*.jpg\")\n",
    "extras_use_prefix = '~/data/images_clipped_buffered_augmented_use/'\n",
    "use_prefix = 'images_clipped_buffered_augmented_use/'\n",
    "extras_use = glob.glob(f\"{extras_use_prefix}**/**/*.jpg\")\n",
    "extras_security_prefix = '~/data/images_clipped_buffered_augmented_security/'\n",
    "security_prefix = 'images_clipped_buffered_augmented_security/'\n",
    "extras_security = glob.glob(f\"{extras_security_prefix}**/**/*.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2114e05",
   "metadata": {},
   "source": [
    "#### Add the augmented images\n",
    "Add new rows to dataframes where augmented images exist, basing all fields on their original un-augmented image counterpart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat this for each class\n",
    "for e in extras_security:\n",
    "    et = e.split('/')[-3:]\n",
    "    eb = '/'.join(e.split('/')[-3:])\n",
    "    print(f\"{prefix_to_add}{eb[:-6] + '.jpg'}\")\n",
    "    index_found = df_filtered[df_filtered['file_name'] == f\"{prefix_to_add}{eb[:-6] + '.jpg'}\"].index\n",
    "     \n",
    "    if not index_found.empty:\n",
    "        existing_row_index = index_found[0]\n",
    "        existing_row = df_filtered.loc[existing_row_index]\n",
    "        new_row = df_filtered.loc[existing_row_index].copy()\n",
    "\n",
    "        new_row['file_name'] = f\"{security_prefix}{eb}\"\n",
    "\n",
    "        df_filtered = pd.concat([df_filtered, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        print(\"No matching rows found for\", f\"{prefix_to_add}{eb[:-6] + '.jpg'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae49ebb",
   "metadata": {},
   "source": [
    "#### Weight the rows by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da23240e-7d92-4ad0-bd4c-0aee89928d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column, setting all to 1 to start\n",
    "df[\"weights\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801eb0b",
   "metadata": {},
   "source": [
    "Selectively up-weight the classes in need of more sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406768a-df01-4f94-b541-9e6dac1fcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value to compare\n",
    "target_status = 'secured'\n",
    "\n",
    "# Find rows where 'Status' column equals the target value\n",
    "filtered_rows = df[df['security'] == target_status]\n",
    "\n",
    "# Assign a new value to another column ('NewColumn') for those rows\n",
    "df.loc[filtered_rows.index, 'weights'] = 1 # Or 2,3, etc depending on relative sparsity\n",
    "\n",
    "print(df['weights'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bd78850f-9623-4698-b126-38b2f7117e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_security_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752e415-8d57-4aef-ac69-4073a8479124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
