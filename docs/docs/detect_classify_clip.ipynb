{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "This Python script performs object detection and classification on images using Detectron2 and a custom classification model. It loads a pre-trained object detection model, detects objects in images, clips the detected regions, and then classifies the clipped regions using a separate classification model. The results are saved to CSV files.\n",
    "\n",
    "#### Components\n",
    "\n",
    "- **load_configuration**: Function to load configuration options from a YAML file.\n",
    "- **clip_image_around_bbox_buffer**: Function to clip an image around a bounding box with a buffer.\n",
    "- **load_classification_model**: Function to load a classification model from a checkpoint file.\n",
    "- **evaluate_classification_model**: Function to evaluate a classification model on an image.\n",
    "- **main**: Main function for object detection and classification.\n",
    "\n",
    "#### Usage\n",
    "\n",
    "To run the script `detect_classify_clip.py`, execute it from the command line with the following arguments:\n",
    "\n",
    "1. **images_dir**: Directory containing dataset images.\n",
    "2. **detector_cpkt_path**: Path to the object detection model checkpoint file.\n",
    "3. **classification_ckpt_path**: Path to the classification model checkpoint file.\n",
    "4. **output_dir**: Directory to save output files.\n",
    "\n",
    "Example command:\n",
    "\n",
    "```bash\n",
    "python detect_classify_clip.py images/ detector_model.pth classification_model.pth output/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual results\n",
    "\n",
    "![alt text](images/detect_classify_pred0_tTRGjavPoSelZNYc1O2qbu_left_254330320664391_left.png)\n",
    "![alt text](images/detect_classify_pred11_4r8Be9MPU03VNa16QWfTGO_right_881083906861807_right.png)\n",
    "![alt text](images/detect_classify_pred3_Pg5loJ2tx1B8ZYzEU4NpfC_left_1012573259800054_left.png)\n",
    "![alt text](images/detect_classify_pred8_IVRwdhS1g08YiHm4t23JTA_left_265829086071996_left.png)\n",
    "![alt text](images/detect_classify_pred4_0mQlNMAy4x6C7hZJcGXWOe_left_332634499403525_left.png)\n",
    "![alt text](images/detect_classify_pred6_NvChPFk9mfMrldz0WRgGbH_right_804625321456050_right.png)\n",
    "![alt text](images/detect_classify_pred13_2EBrjKYZlWkm7nOFpMA5i8_left_835715341581970_left.png)\n",
    "![alt text](images/detect_classify_pred12_Pg5loJ2tx1B8ZYzEU4NpfC_right_1356927844943950_right_1.png)\n",
    "![alt text](images/detect_classify_pred2_2EBrjKYZlWkm7nOFpMA5i8_left_251740414247834_left_1.png)\n",
    "![alt text](images/detect_classify_pred10_tTRGjavPoSelZNYc1O2qbu_right_1246075890128886_right.png)\n",
    "![alt text](images/detect_classify_pred7_KUeyNt9kjrsMzlJ8X2dmf0_left_2226435360894990_left.png)\n",
    "![alt text](images/detect_classify_pred14_4r8Be9MPU03VNa16QWfTGO_left_3190611904573392_left.png)\n",
    "![alt text](images/detect_classify_pred5_wg47LWeMDXvsERoYrQB8hG_right_1072653617082899_right.png)\n",
    "![alt text](images/detect_classify_pred1_toOC03Pxcn51gwvyGVHrMW_left_369043715529607_left_1.png)\n",
    "![alt text](images/detect_classify_pred14_pHTQL7F3a2WCZJnwx4di0y_left_259487610432232_left.png)\n",
    "![alt text](images/detect_classify_pred15_8qTcoVK6MZFdCJXLGgnk35_right_1230875951637787_right.png)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
