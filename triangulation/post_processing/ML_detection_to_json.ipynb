{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 1 Streetview image GPS \n",
    "\n",
    "Filter and rename Padang streeview imges GPS file.\n",
    "\n",
    "\n",
    "## Step 2 Create individule streetview detection json\n",
    "\n",
    "Filtered detection results by their optimal confident score for building properties, but we are using 0.5 as the threshod for building parts classes. \n",
    "\n",
    "Create the json file to save individule streetview image, so we can ingest them to PostgreSQL databases. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_parts = \"results-padang-building-parts.csv\"\n",
    "b_properties = \"results-padang-building-properties.csv\"\n",
    "sv_gps= \"post_processing/padang_coordinate_filtered.csv\"\n",
    "b_footprint= \"padang_footprints/padang_footprints_fixed.geojson\"\n",
    "model_stats = 'model_evaluation_hp_padang_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transform detected objects from image to map coordinates\n",
    "\n",
    "@author: developmentseed\n",
    "\"\"\"\n",
    "import os \n",
    "from os import makedirs, path as op\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from pyproj import Geod\n",
    "from shapely.geometry import shape, LineString, GeometryCollection\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Streetview image GPS \n",
    "\n",
    "Filter and rename Padang streeview imges GPS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_big_csv(csv, columns=None):\n",
    "    \"\"\"filter and rename tractory csv files\n",
    "    \n",
    "    Args:\n",
    "        csv: csv file that contains gps coordination \n",
    "        \n",
    "    Returns:\n",
    "        df: exported dataframe filtered columns and renamed\n",
    "    \"\"\"\n",
    "    # csv is more than 500MB, so read data in chunks e.g. 5000 rows per chunk\n",
    "    c_size = 5000\n",
    "    if columns:\n",
    "        select_cols = ['HEADING', 'IMAGE_ID', 'LAT', 'LONG']\n",
    "        df_chunks_lst = [chuck_df for chuck_df in pd.read_csv(csv, \n",
    "                                    chunksize=c_size, skipinitialspace=True, usecols=select_cols)]\n",
    "    else:\n",
    "        df_chunks_lst = [chuck_df for chuck_df in pd.read_csv(csv, \n",
    "                                    chunksize=c_size, skipinitialspace=True)]\n",
    "    \n",
    "    df = pd.concat(df_chunks_lst)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Create individule streetview detection json\n",
    "\n",
    "Filtered detection results by their optimal confident score for building properties, but we are using 0.5 as the threshod for building parts classes. \n",
    "\n",
    "Create the json file to save individule streetview image, so we can ingest them to PostgreSQL databases. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_csv(model_stats)\n",
    "df_model = df_model.sort_values(by='threshold score', ascending=False)\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_values(values, optimal_score):\n",
    "    \"\"\"filter detection by the optimal score\n",
    "    \n",
    "    Args:\n",
    "        detection: the detection for each images\n",
    "    Returns:\n",
    "        new\n",
    "    \"\"\"\n",
    "    values = ast.literal_eval(values)\n",
    "    new_dict = dict(detection_scores=[],\n",
    "       detection_classes =[],\n",
    "       detection_boxes = [], \n",
    "                   image_fname=None)\n",
    "    for detection in values:\n",
    "        if float(detection['detection_scores'])>= float(optimal_score[int(detection['detection_classes'])]):\n",
    "            print(int(detection['detection_classes']), detection['detection_scores'], detection['detection_boxes'])\n",
    "            new_dict['detection_scores'].append(detection['detection_scores'])\n",
    "            new_dict['detection_classes'].append(int(detection['detection_classes']))\n",
    "            new_dict['detection_boxes'].append(detection['detection_boxes'])\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_detection_by_optimal_score(optimal_score, df, output_dir, col = ['tile', 'output']):\n",
    "    \"\"\"filter dataframe values by the given threshold\n",
    "    \n",
    "    Args:\n",
    "        optimal_score: dictionary include the optimal key and value;\n",
    "        df: the target dataframe\n",
    "    \n",
    "    Returns:\n",
    "        (None): write each row into json file\n",
    "    \"\"\"\n",
    "    df2dict = dict(zip(df[col[0]], df[col[1]]))\n",
    "    for key, value in df2dict.items():\n",
    "        new_dict = _filter_values(value, optimal_score)\n",
    "        new_dict['image_fname']=key\n",
    "        if not op.isdir(output_dir):\n",
    "            makedirs(output_dir)\n",
    "        nm = op.splitext(op.basename(key))[0]\n",
    "        out_file = op.join(output_dir, f\"{nm}.json\")\n",
    "        if op.isfile(out_file):\n",
    "            continue\n",
    "        else:\n",
    "            with open(out_file, 'w') as f:\n",
    "                json.dump(new_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dict = dict(zip(df_model['cls_id'], df_model['threshold score']))\n",
    "filter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_properties = read_big_csv(b_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_detection_by_optimal_score( filter_dict, df_b_properties, \"building_properties_sv_inferences_resluts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_parts = read_big_csv(b_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dict_parts = {1:0.5, 2:0.5, 3:0.5, 4:0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_detection_by_optimal_score(filter_dict_parts, df_b_parts, \"building_parts_sv_inferences_resluts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding `cam` info to streetview geolocation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_gps = read_big_csv(sv_gps)\n",
    "sv_gps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only sv image that taken by Cam1 and Cam3. \n",
    "sv_gps = sv_gps.loc[(sv_gps['IMAGE_ID'].apply(lambda x: x.split('_')[6] in cams.keys()))]\n",
    "sv_gps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding cam to the dataframe\n",
    "sv_gps['cam'] = sv_gps['IMAGE_ID'].apply(lambda x: cams[x.split('_')[6]])\n",
    "sv_gps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_gps.to_csv(\"padang_coordinate_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
